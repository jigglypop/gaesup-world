## 제3장 확률적 블랙박스 최적화: ES 유도와 교전 거리 분포 정합

> 본 문서는 **LB-IGD (Laplace–Beltrami Inverse Game Design)** 관련 이론 문서입니다. (구현 코드: 미포함)
>
> - 관련 문서: 제1장 `docs/brain/bellman.md`, 제2장 `docs/brain/lbo.md`, 제4장 `docs/brain/evaluation.md`
> - 코드 대응: (미포함)

### 초록
설계 변수 \(x\)는 게임(MDP) \(\mathcal{M}_x\)를 정의합니다. 그리고 그 게임에서 self-play로 학습된 정책 \(\pi_x^*\)를 통해 통계 \(y(x;\omega)\)를 관측하고, 이를 바탕으로 “밸런스 손실” \(L\)을 계산합니다. 이 구조는 내부에 학습이 들어가고(내부 루프), 외부에서는 설계를 바꾸는(외부 루프) 형태이므로 본질적으로 **확률적 bilevel(2중) 최적화**입니다.

이 장에서는 다음을 설명합니다.

- (i) 왜 \(J(x)=\mathbb{E}[L(y(x;\omega))]\)가 “노이즈가 있는 black-box 목적함수”가 되는지
- (ii) 왜 일반적인 gradient descent를 그대로 쓰기 어려운지(이산/비연속/학습 노이즈)
- (iii) 함수값만으로 방향을 추정하는 ES(Score Function Estimator) 유도와, 분산 감소(대칭 샘플링/CRN)의 의미

마지막으로 (iv) 밸런스를 “교전 거리 분포의 정합” 관점으로도 볼 수 있음을 보이고, 1차원에서는 정렬 기반으로 계산 가능한 Wasserstein 거리 \(W_2\)를 목적함수 구성에 쓰는 방법을 정리합니다.

### 1. 외부 문제의 최소 정식화: $x \mapsto y(x;\omega)$
설계 문제는 다음의 형태로 정리할 수 있습니다.

$$
x \in \mathcal{X}
\;\longmapsto\;
y(x;\omega)
\;\longmapsto\;
L(y(x;\omega)).
$$

- $x$: 설계 변수(맵 구조, 거리, 면적, 병목, 유닛 파라미터 등)
- $y(x;\omega)$: self-play 및 학습을 통해 측정되는 통계(승률, 평균 교전 거리, 교전 빈도 등)
- $\omega$: 시드, 초기화, 탐색 노이즈, 학습의 확률성을 나타내는 외생 변수

외부 목적함수는 기대값으로 정의합니다.

$$
J(x) = \mathbb{E}_\omega\big[L(y(x;\omega))\big],
\qquad
x^* \in \arg\min_{x\in\mathcal{X}} J(x).
$$

이 구조에서 강화학습은 \(y(x;\omega)\)를 계산하는 “내부 평가 절차”로 포함되고, 외부 문제는 \(J(x)\)를 최소화하는 설계 최적화로 남습니다.


### 2. 확률적 함수로서의 $J(x)$
동일한 $x$에 대해서도 self-play 결과는 재현성 오차를 갖는다(근사 최적화, 탐색/초기화 차이, 매칭 표본 차이 등).

$$
y(x;\omega)\ \text{는 확률 변수이며},\quad
J(x)=\mathbb{E}_\omega[L(y(x;\omega))]\ \text{는 확률적 기대 목적함수이다}.
$$

따라서 외부 최적화는 “노이즈가 있는 black-box 함수 최소화”로 분류된다.


### 3. 왜 일반적인 gradient descent가 직접 적용되지 않는가
외부 평가 절차는 대략 다음 합성으로 표현된다.

$$
x
\xrightarrow{\;\text{game generation}\;}
\mathcal{M}_x
\xrightarrow{\;\text{RL/self-play}\;}
\pi_x^*
\xrightarrow{\;\text{statistics}\;}
y(x;\omega)
\xrightarrow{\;\text{loss}\;}
L.
$$

이 합성은 다음 이유로 미분 가능성을 보장하기 어렵다.

- **이산/혼합 변수**: $x$가 이산 구조(예: 성 배치, 경로 연결)와 연속 변수(예: 거리, 면적)를 동시에 포함할 수 있다.
- **비연속적 정책 변화**: 작은 $x$ 변화가 학습된 전략을 질적으로 바꾸어 $y(x)$가 불연속적으로 변할 수 있다.
- **학습 자체의 비미분성**: 실제 RL 구현은 샘플링, 클리핑, 리플레이, 근사 최적화 등으로 인해 $x \mapsto \pi_x^*$를 매끄러운 함수로 간주하기 어렵다.

따라서 외부에서 안정적인 $\nabla_x J(x)$를 직접 계산하는 접근은 일반적으로 실패하거나 매우 불안정하다.

### 3.1 (구현 관점) 이산 설계변수(패턴 ID, 유닛 수)와 “투영(projection)”
실제 게임 설계에서는 다음과 같은 변수가 흔히 **이산/정수**이다.

- 유닛 수: $p_{f,i}^{(\text{units})}\in\mathbb{Z}_{\ge 0}$
- 이동 패턴 선택: $p_{f,i}^{(\text{pattern})}\in\{0,1,\ldots,P-1\}$

그러나 ES 유도(4절)는 보통 $x\in\mathbb{R}^d$의 연속 벡터를 가정한다. 실무에서는 이를 다음처럼 처리한다.

1) ES는 연속 벡터 $x$를 업데이트한다(가우시안 섭동, 차분).
2) 환경을 실제로 평가할 때는, $x$를 **정수화/클램프**하여 유효 설계 $\Pi(x)$로 투영한다.

즉, 실제로 값으로만 평가되는 목적함수는

$$
\hat J(\Pi(x))
$$

가 된다. 이는 엄밀한 의미의 미분 가능성을 만들지는 않지만, 본 문제는 애초에 “값으로만 평가 가능한 black-box”이므로 ES의 사용 목적(근사 방향 탐색)과 충돌하지 않는다.

중요한 실무 포인트는 다음이다.

- **클램프는 최적화의 일부**로 간주하고 고정해야 한다: 후보마다 다른 정수화 규칙은 비교 공정성을 깨뜨린다.
- **정수화로 인한 노이즈를 완화**하려면: (i) 평가 표본을 늘리거나, (ii) 대칭 표본(antithetic)과 CRN을 사용하거나, (iii) 작은 예산→큰 예산 멀티-피델리티를 사용한다(13절 참조).

### 4. ES(Score Function Estimator)의 유도
외부 목적함수 $J(x)$가 비미분적이더라도, **평활화(smoothing)** 를 통해 “근사적으로 미분 가능한 목적함수”를 만들 수 있다.

#### 4.1 가우시안 평활화된 목적함수
$\epsilon \sim \mathcal{N}(0, I)$라 두고,

$$
J_\sigma(x) = \mathbb{E}_{\epsilon}\big[J(x+\sigma\epsilon)\big]
$$

를 정의한다($\sigma > 0$). 여기서 $J_\sigma$는 $J$의 가우시안 컨볼루션으로 이해할 수 있다.

이 정의는 “설계공간에서의 평활화(확산)”라는 관점에서도 해석할 수 있습니다. 즉, $\sigma$를 줄이면 $J_\sigma$는 원래 목적함수 $J$로 돌아가며(형식적으로 $\sigma \to 0$ 한계), $\sigma$가 클수록 더 강하게 매끈해진 대체 목적이 됩니다. 따라서 $J_\sigma$를 기준으로 한 곡률/민감도 측정(라플라시안, 2차 차분)은 원래 문제를 바꾸는 것이 아니라, **노이즈가 큰 black-box 목적을 안정적으로 다루기 위한 상위호환 정식화**로 볼 수 있습니다.

또한 유클리드 연속 공간에서 $t=\sigma^2/2$로 두고 $u(t,x):=\mathbb{E}[J(x+\sqrt{2t}\,\epsilon)]$로 정의하면, $u$는 초기조건 $u(0,x)=J(x)$를 갖는 열방정식(확산 방정식)

$$
\partial_t u(t,x)=\Delta u(t,x)
$$

의 해입니다(가우시안 커널 컨볼루션의 표준 성질). 이 관점에서 **라플라시안 \(\Delta\)** 는 “가우시안 평활화(확산)”의 생성자(generator)로 정확히 대응합니다.

동치적으로 $u = x+\sigma\epsilon$를 두면 $u \sim \mathcal{N}(x,\sigma^2 I)$이므로,

$$
J_\sigma(x) = \mathbb{E}_{u \sim \mathcal{N}(x,\sigma^2 I)}[J(u)].
$$

#### 4.2 로그-우도 트릭을 이용한 그라디언트
확률밀도 $p(u\mid x)=\mathcal{N}(u; x,\sigma^2 I)$에 대해,

$$
J_\sigma(x) = \int J(u)\,p(u\mid x)\,du.
$$

양변을 $x$로 미분하면

$$
\nabla_x J_\sigma(x)=\int J(u)\,\nabla_x p(u\mid x)\,du
=\int J(u)\,p(u\mid x)\,\nabla_x \log p(u\mid x)\,du.
$$

즉,

$$
\nabla_x J_\sigma(x) = \mathbb{E}_{u\sim \mathcal{N}(x,\sigma^2 I)}\big[J(u)\,\nabla_x \log p(u\mid x)\big].
$$

가우시안의 로그밀도는

$$
\log p(u\mid x) = -\frac{1}{2\sigma^2}\|u-x\|_2^2 + C
$$

이므로,

$$
\nabla_x \log p(u\mid x) = \frac{u-x}{\sigma^2}.
$$

그런데 $u=x+\sigma\epsilon$이므로 $(u-x)/\sigma^2 = \epsilon/\sigma$. 따라서

$$
\nabla_x J_\sigma(x)=\frac{1}{\sigma}\,\mathbb{E}_{\epsilon\sim\mathcal{N}(0,I)}\big[J(x+\sigma\epsilon)\,\epsilon\big]
$$

이는 $J$가 미분 불가능하더라도 “함수값 평가”만으로 그라디언트를 근사하는 핵심 공식이다.

## 4.3 몬테카를로 추정기
표본 $\epsilon_1,\ldots,\epsilon_K \sim \mathcal{N}(0,I)$를 사용하면

$$
\widehat{\nabla_x J_\sigma}(x)=\frac{1}{K\sigma}\sum_{k=1}^{K} J(x+\sigma\epsilon_k)\,\epsilon_k
$$

로 추정할 수 있다. 분산 감소를 위해 $J(x+\sigma\epsilon_k)$에서 배이스라인(예: 표본 평균)을 빼는 것이 일반적이다.

#### 4.4 베이스라인(baseline)에 의한 분산 감소(불편성 유지)
상수 $b$를 임의로 택하면 다음 추정기는 동일한 기댓값을 갖는다.

$$
\frac{1}{\sigma}\,\mathbb{E}_{\epsilon}\big[(J(x+\sigma\epsilon)-b)\,\epsilon\big]
=
\frac{1}{\sigma}\,\mathbb{E}_{\epsilon}\big[J(x+\sigma\epsilon)\,\epsilon\big].
$$

이는 $\mathbb{E}_\epsilon[\epsilon]=0$이므로

$$
\mathbb{E}_\epsilon[b\,\epsilon]=b\,\mathbb{E}_\epsilon[\epsilon]=0
$$

가 성립하기 때문이다. 실무적으로는 $b$를 배치 평균, 이동평균 등으로 설정하여 분산을 낮춘다.

#### 4.5 대칭 표본(antithetic sampling)에 의한 분산 감소
$\epsilon$와 $-\epsilon$을 쌍으로 사용하면 대칭성이 강화되어 분산이 감소하는 경우가 많다. 예를 들어 다음 추정기는 $K/2$개의 i.i.d. 표본 $\epsilon_k$만으로 계산된다.

$$
\widehat{\nabla_x J_\sigma}(x)
 =
 \frac{1}{K\sigma}\sum_{k=1}^{K/2}\Big(J(x+\sigma\epsilon_k)-J(x-\sigma\epsilon_k)\Big)\,\epsilon_k.
$$

이 형태는 “차분을 통한 잡음 상쇄” 효과를 제공하며, 수치적으로도 안정적이다(평가 노이즈가 큰 경우에 유리).

---

### 5. “거리/공간” 변수가 핵심이 되는 이유: 분포 관점의 환원
외부 목적함수 $J(x)$의 난이도는 “$x$ 변화가 관측 통계 $y(x)$에 만드는 효과가 얼마나 매끄러운가”에 크게 좌우된다. 스탯 기반 변수(공격력, 방어력 등)는 고차원 상호작용으로 인해 메타가 불연속적으로 전환되기 쉽다. 반면 거리/면적/병목 같은 공간 변수는 교전이 발생하는 기하학적 조건을 직접 바꾸어, 관측 통계의 변화를 상대적으로 연속적으로 만들 가능성이 높다.

이를 정식화하기 위해, 교전 거리 $d \in \mathbb{R}_{\ge 0}$를 확률 변수로 두고, 설계 $x$가 만드는 교전 거리 분포를

$$
p_x(d) \quad (\text{또는 } D_x)
$$

로 정의한다.


### 6. 승률을 “거리 분포의 함수”로 근사하기
각 팩션 $f$가 특정 거리 $d$에서 가지는 상대적 유리함을 스칼라 함수 $u_f(d)$로 모델링하자(예: 유효 사거리와 교전 거리의 차이에 의해 결정되는 효용).

그러면 승률은 다음과 같은 기대값 형태로 근사될 수 있다.

$$
W_f(x) \;\approx\; \mathbb{E}_{d\sim p_x}\big[u_f(d)\big]
 \;=\; \int u_f(d)\,p_x(d)\,dd.
$$

이 근사는 “승패가 수많은 국면 요인의 합성”이라는 현실을 단순화하지만, 설계 변수와 밸런스 사이의 연결을 명시적으로 만든다는 점에서 유용하다.


### 7. 분포 정합으로서의 밸런스: 목표 분포 $\bar q$
팩션 $f$가 선호하는 교전 거리의 “목표 분포”를 $q_f(d)$로 두자. 예를 들어,

$$
q_f(d) = \mathcal{N}(d; R_f, \sigma_f^2)
$$

는 평균 교전 거리 $R_f$와 허용 분산 $\sigma_f^2$를 갖는 가우시안 목표를 의미한다.

여러 팩션을 동시에 공정하게 만들고자 한다면, 전체 목표 분포를 혼합으로 둘 수 있다.

$$
\bar q(d) = \frac{1}{F}\sum_{f=1}^{F} q_f(d).
$$

직관적으로 $p_x \approx \bar q$이면 “교전이 특정 한 거리대에 과도하게 몰리지 않고, 다양한 거리대가 충분히 등장”하게 되며, 각 팩션의 $u_f(d)$가 받는 기대값이 평탄화될 가능성이 높다.

---

### 8. Wasserstein 거리 $W_2$ 기반 목적함수
“$p_x$와 $\bar q$가 가깝다”를 수치화하기 위해 Wasserstein 거리 $W_2$를 사용할 수 있다.

#### 8.1 1차원에서의 $W_2$ 정의(정량적 정합)
1차원에서 두 분포 $P,Q$의 $W_2$는 누적분포함수 $F,G$의 역함수(quantile)로 다음처럼 쓸 수 있다.

$$
W_2^2(P,Q)
 =
 \int_{0}^{1} \big(F^{-1}(t)-G^{-1}(t)\big)^2\,dt.
$$

이 정의는 “확률질량을 최적으로 옮길 때의 제곱 비용”을 의미하며, 히스토그램/경험분포에도 자연스럽게 적용된다.

#### 8.2 가우시안 사이의 폐형식(1차원)
특히 $P=\mathcal{N}(m_1,s_1^2)$, $Q=\mathcal{N}(m_2,s_2^2)$일 때, 1차원에서는 다음이 성립한다.

$$
\boxed{W_2^2(P,Q) = (m_1-m_2)^2 + (s_1-s_2)^2}.
$$

유도는 다음과 같다. 표준정규 CDF를 $\Phi$라 하면, 가우시안의 quantile은

$$
F^{-1}(t) = m_1 + s_1 \Phi^{-1}(t),\qquad
G^{-1}(t) = m_2 + s_2 \Phi^{-1}(t).
$$

이를 정의식에 대입하면

$$
W_2^2(P,Q)
=
\int_0^1 \Big((m_1-m_2) + (s_1-s_2)\Phi^{-1}(t)\Big)^2 dt.
$$

여기서 $Z=\Phi^{-1}(U)$이고 $U\sim \mathrm{Unif}(0,1)$이면 $Z\sim \mathcal{N}(0,1)$이므로,

$$
\int_0^1 \Phi^{-1}(t)\,dt = \mathbb{E}[Z]=0,\qquad
\int_0^1 (\Phi^{-1}(t))^2\,dt = \mathbb{E}[Z^2]=1.
$$

따라서 교차항이 사라지고 위의 폐형식이 얻어진다.

#### 8.3 제안 목적함수(예시)
분포 정합을 직접 목표로 삼으면 다음과 같은 외부 목적을 둘 수 있다.

$$
J_{\text{dist}}(x) = \mathbb{E}_\omega\big[ W_2^2(p_x(\cdot;\omega), \bar q) \big].
$$

혹은 승률 기반 손실과 결합하여,

$$
J(x) = \mathbb{E}_\omega\big[L_{\text{win}}(x;\omega)\big]
 + \lambda\,\mathbb{E}_\omega\big[ W_2^2(p_x(\cdot;\omega), \bar q) \big]
$$

와 같이 “결과(승률)”와 “원인(거리 분포)”를 함께 제어할 수도 있다.

---

### 9. 경험분포에서의 $W_2$ 계산(1차원)
실제 self-play 로그로부터 얻는 것은 분포의 파라미터가 아니라 표본이다. 1차원에서 경험분포끼리의 $W_2$는 정렬 기반으로 계산할 수 있다.

#### 9.1 동일 가중치 경험분포의 정렬 기반 공식
두 경험분포가 각각 표본

$$
\{d_i\}_{i=1}^{N},\qquad \{\tilde d_i\}_{i=1}^{N}
$$

로 주어지고 동일 가중치를 갖는다고 하자. 정렬된 표본을 $d_{(1)}\le\cdots\le d_{(N)}$, $\tilde d_{(1)}\le\cdots\le \tilde d_{(N)}$라 하면,

$$
\boxed{
W_2^2(\hat P,\hat Q) = \frac{1}{N}\sum_{i=1}^{N}\big(d_{(i)}-\tilde d_{(i)}\big)^2
}
$$

가 성립한다. 이는 1차원 optimal transport에서 최적 매칭이 단조 수송(monotone coupling)으로 주어지기 때문이다.

> 구현 메모: (미포함) 1차원 경험표본의 \(W_2^2\)는 “정렬 기반” 공식을 사용한다.

#### 9.2 목표 분포가 혼합분포인 경우
목표 $\bar q(d)=\frac{1}{F}\sum_f q_f(d)$는 일반적으로 혼합분포이며 폐형식 $W_2$가 존재하지 않을 수 있다. 이때는 다음 중 하나를 사용한다.

- $\bar q$에서 표본 $\{\tilde d_i\}_{i=1}^{N}$를 샘플링한 뒤 9.1의 공식을 적용하여 $W_2^2(\hat p_x, \bar q)$를 몬테카를로 근사한다.
- 목표 분포를 단일 가우시안으로 근사하여 8.2의 폐형식을 사용한다(근사 오차가 허용될 때).

---

### 10. 실측 관점: $p_x(d)$를 어떻게 추정하는가
실제 self-play 데이터로부터 $p_x(d)$는 다음 절차로 경험적으로 구성할 수 있다.

- 교전 이벤트마다 교전 거리 $d_i$를 기록한다.
- 충분한 수의 교전 표본 $\{d_i\}_{i=1}^N$을 수집한다(여러 시드/매칭에서 반복).
- 히스토그램/커널밀도추정 등을 통해 경험분포 $\hat p_x$를 만든다.
- $\hat p_x$와 $\bar q$ 사이의 $W_2$를 계산한다(1차원 경험분포는 정렬 기반으로 계산 가능).

---

### 11. 논의: 퇴화 해(degenerate solution)와 제약의 필요성
분포 정합(또는 승률 평탄화)만을 목표로 하면, 생각보다 쉽게 “의미 없는 해”로 빠질 수 있습니다. 예시는 아래와 같습니다.

- 교전 자체가 거의 발생하지 않도록 설계하여 $p_x(d)$가 의미 없는 분포가 되게 만드는 경우
- 극단적으로 긴/짧은 게임 길이로 승률 분산이 인위적으로 감소하는 경우

따라서 실무적 목적함수 \(J(x)\)에는 참여도(engagement), 게임 길이 범위, 이벤트 발생률, 난이도, 비용 같은 제약 항을 함께 넣는 것이 바람직합니다.

### 12. 연결: “역설계(inverse design)”로 확장하기
위 논의는 \(q_f\)(각 팩션이 선호하는 거리대)가 주어졌다고 가정했습니다. 제5장(`inverse.md`)에서는 “목표 플레이 패턴”으로부터 \(q_f\) 및 팩션 파라미터 자체를 학습/생성하는 inverse game design 문제로 확장하고, 분포 정합을 정보기하 관점에서 정리합니다.

---

### 13. 실행 가능한 외부 최적화 루프(ES) 설계: 프로토콜·제약·분산 감소를 포함한 최소 형태
앞 절들에서 유도한 ES는 “\(J(\cdot)\)를 값으로만 평가할 수 있다”는 조건에서 유효합니다. 그런데 이 프로젝트의 \(J(x)\)는 self-play/RL을 포함하므로, **평가 프로토콜과 제약을 함께 포함**시켜야 퇴화 해를 배제하면서 재현 가능한 최적화를 수행할 수 있습니다(`evaluation.md`와 연결).

#### 13.1 고정해야 하는 평가 프로토콜(필수)
설계 후보를 공정하게 비교하려면 다음을 명시적으로 고정해야 합니다.

- 내부 학습 예산 $B$(스텝/시간/게임 수)
- 정책 초기화 방식(항상 재학습 vs warm-start)
- 매칭 구성(라운드로빈/리그/대칭 매칭 등)
- 시드 반복 수 $S$ 및 시드 생성 규칙

이 프로토콜을 고정한 뒤, 각 후보 $x$에 대해 다음을 반복 관측한다.

$$
\hat J(x)
:=
\frac{1}{S}\sum_{s=1}^{S}
\Big(
L_{\text{win}}(x;\omega_s)
 + \lambda\,L_{\text{meta}}(x;\omega_s)
 + \beta\,R(x;\omega_s)
\Big).
$$

여기서 $L_{\text{win}}$은 승률 기반 밸런스 손실(예: `evaluation.md`의 $L_{\text{pair}}$ 또는 $L_{\text{win}}$), $L_{\text{meta}}$는 분포 기반 보조 손실이며 예를 들어
$$
L_{\text{meta}}(x;\omega):=W_2^2\big(\hat p_x(\cdot;\omega),\,q^\star\big)
$$
로 둘 수 있다. 다팩션 목표가 혼합분포로 주어지면 $q^\star=\bar q$로 둘 수 있다(7절의 목표 분포). 또한 $\hat J(x)$는 고정된 프로토콜에서 $S$회 시드 반복으로 계산한 $J(x)$의 몬테카를로 추정치이다. $R$은 퇴화 해 방지 제약(교전 발생률/게임 길이 등)이다.

#### 13.2 퇴화 해 방지 제약 $R(x;\omega)$ (권장 최소)
승률 평탄화 또는 분포 정합만을 최소화하면 “의미 없는 50:50”이 최적해로 선택될 수 있다. 따라서 다음을 최소 제약으로 둔다.

- 교전 이벤트 발생률 하한(예: 게임당 교전 이벤트 수 $\ge c_{\min}$)
- 게임 길이 범위(예: 평균 길이 $\in [T_{\min},T_{\max}]$)
- (존재한다면) 무승부/정지 상태 비율 상한

제약은 보통 힌지(hinge) 형태의 페널티로 구현해 $R(x;\omega)$에 합산한다.

#### 13.3 ES 업데이트(대칭 샘플 권장)
외부 변수 $x$에 대해 $K/2$개 표준 정규 표본 $\epsilon_k\sim\mathcal{N}(0,I)$를 뽑고, 대칭 후보 $x\pm\sigma\epsilon_k$를 평가한다.

$$
\widehat{\nabla_x J_\sigma}(x)
=
\frac{1}{K\sigma}\sum_{k=1}^{K/2}
\Big(\hat J(x+\sigma\epsilon_k)-\hat J(x-\sigma\epsilon_k)\Big)\epsilon_k.
$$

이후 $x\leftarrow x-\alpha\,\widehat{\nabla_x J_\sigma}(x)$로 갱신한다(스텝 선택/클리핑은 구현 선택).

#### 13.4 비용·분산을 줄이는 “프로토콜 내” 기법(black-box 가정 유지)
다음 기법들은 ES 유도와 모순되지 않으면서 실측 분산과 비용을 줄이는 데 유효하다.

- **공통 난수(Common Random Numbers; CRN)**: 동일 반복 $s$에 대해 후보들에 같은 시드/매칭을 부여해 $\hat J$의 “차이” 분산을 낮춘다.
- **멀티-피델리티(저예산→고예산)**: 작은 $B$로 후보를 거른 뒤 상위 후보만 큰 $B$로 확정한다.
- **조기 종료(early stop)**: 제약 위반이 큰 후보는 즉시 중단해 퇴화 해를 빠르게 컷한다.

warm-start를 사용할 경우, 그 자체가 $\omega$의 구조(히스토리 의존성)를 바꾸므로 “평가 프로토콜의 일부”로 명시하고 고정해야 한다(`bellman.md`의 마르코프성 논의와 연결).
